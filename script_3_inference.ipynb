{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8de2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f41de3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## download data test.csv and model model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5c45895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client(\n",
    "    's3', \n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name='us-east-2'\n",
    ")\n",
    "\n",
    "# S3 bucket details\n",
    "bucket_name = 'mle-e2e-1'\n",
    "\n",
    "# Download test.csv from S3\n",
    "test_file = 'inputs/test.csv'\n",
    "local_test_file = 'inputs/test.csv'\n",
    "s3.download_file(bucket_name, test_file, local_test_file)\n",
    "\n",
    "# Download the model from S3\n",
    "model_file = 'models/model.pkl'\n",
    "local_model_file = 'models/model.pkl'\n",
    "s3.download_file(bucket_name, model_file, local_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2554a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d85be740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset and the model\n",
    "test_data = pd.read_csv(local_test_file)\n",
    "model = joblib.load(local_model_file)\n",
    "\n",
    "# Predict using the model\n",
    "test_data['y_pred'] = model.predict(test_data[['x']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66bf2a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85b02b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded outputs/inference.csv to S3 bucket mle-e2e-1 under outputs/inference.csv\n"
     ]
    }
   ],
   "source": [
    "# Include x, y_test (actual y values), and y_pred in the output\n",
    "output_data = test_data[['x', 'y', 'y_pred']]\n",
    "output_data.columns = ['x', 'y_test', 'y_pred']\n",
    "\n",
    "# Save the output to a CSV file\n",
    "output_file = 'outputs/inference.csv'\n",
    "output_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Upload the results to S3\n",
    "output_s3_file = 'outputs/inference.csv'\n",
    "s3.upload_file(output_file, bucket_name, output_s3_file)\n",
    "print(f\"Uploaded {output_file} to S3 bucket {bucket_name} under {output_s3_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da3674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30625c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
